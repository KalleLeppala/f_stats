{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import f_stats\n",
    "import numpy\n",
    "G = numpy.array([[0, 0.1, 0.3, 0.8], [0, 0.2, 0.5, 0.9]])\n",
    "pops = numpy.array([\"wolf\", \"bear\", \"lynx\", \"wolverine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You cannot choose output_type = 3 because the statistics coded by the matrix M you gave are not linearly independent and so the covariance matrix of the sample mean is not invertible.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_covariance(G, pops, 1, M = M, names = names, output_type = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = numpy.random.rand(1000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = numpy.concatenate((names, names), 0)\n",
    "M = numpy.concatenate((M, M), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [-1.,  0., -1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 0., -1.,  0., -1.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  0., -1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [-1.,  0., -1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(M, names) = f_stats.f4_basis(pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "########## EXAMPLES #######################################################################################################################\n",
    "\n",
    "# I'm sorry python is so stupid there is no multiline commenting. It makes these examples pretty hard to run.\n",
    "\n",
    "# Example 1)\n",
    "# Just a basic usage of the main function estimator_covariance using fake frequency data made with independent uniform distrihbutions.\n",
    "#\n",
    "# table = numpy.random.rand(100000, 5)\n",
    "# pops = numpy.array([\"bear\", \"wolf\", \"lynx\", \"wolverine\", \"fox\"])\n",
    "# Let's make a basis of f4-statistics.\n",
    "# The default setting would generate a basis of all f-statistics, consisting of f2- and f3-statistics.\n",
    "# We set the output_type to 3 in order to obtain a matrix directly applicable to the R package admixturegraph, and save the results\n",
    "# in a text files starting with the word \"beast\".\n",
    "# f_stats.estimator_covariance(table, pops, 1000, \"f4\", output_type = 3, save = \"beast\")\n",
    "\n",
    "# Example 2)\n",
    "# This sanity check demontrates that when the data is independet samples from a multivariate source with nonm-trivial correlation matrix,\n",
    "# the chosen window size doesn't matter much.\n",
    "# If the data was from independent multivariate source with independent coordinates, the window size would make a difference.\n",
    "# The real genetic data would not be independent samples, but big enough window size (around 10000?) should help with that.\n",
    "#\n",
    "# source_mean = (- 2, - 1, 0, 1, 2)\n",
    "# source_cov = [[1, 2, 3, 4, 5], [2, 4, 6, 8, 10], [3, 6, 9, 12, 15], [4, 8, 12, 16, 20], [5, 10, 15, 20, 25]]\n",
    "# source = numpy.random.multivariate_normal(source_mean, source_cov, 100000)\n",
    "# We want to be inside the unit interval, so let's apply the logistic function.\n",
    "# table = 1/(numpy.exp(source) + 1)\n",
    "# pops = numpy.array([\"bear\", \"wolf\", \"lynx\", \"wolverine\", \"fox\"])\n",
    "# Take a look at the first row of the covariance matrix computed with different widow sizes:\n",
    "# print(f_stats.estimator_covariance(table, pops, 1)[1][:, 0])\n",
    "# print(f_stats.estimator_covariance(table, pops, 10)[1][:, 0])\n",
    "# print(f_stats.estimator_covariance(table, pops, 100)[1][:, 0])\n",
    "# print(f_stats.estimator_covariance(table, pops, 1000)[1][:, 0])\n",
    "# print(f_stats.estimator_covariance(table, pops, 10000)[1][:, 0])\n",
    "\n",
    "# Example 3)\n",
    "# This second sanity check shows that the resampling functions trurly recover the covariance matrix of the sample mean,\n",
    "# which equals the covariance matrix of the underlying random variable divided by the sample size.\n",
    "#\n",
    "# mean = (- 1, 0, 1)\n",
    "# cov = [[1, 2, 3], [2, 4, 6], [3, 6, 9]]\n",
    "# sample = numpy.random.multivariate_normal(mean, cov, 1000).T\n",
    "# print(f_stats.jackknife(sample))\n",
    "# print(f_stats.bootstrap(sample))\n",
    "\n",
    "########## THE MAIN FUNCTION  #############################################################################################################\n",
    "\n",
    "# estimator_covariance\n",
    "# The function estimator_covariance is the main function using the other functions. Given either allele counts of individuals or allele\n",
    "# frequencies of populations, it will compute the sample mean of a selected collection of second degree homogeneous polynomials, like some\n",
    "# f2-, f3- or f4-statistics, and use block resampling methods to estimate the covariance matrix of this sample mean (NOT the covariance\n",
    "# matrix of the underlying multidimensional random variable, which is the covariance of the sample mean times the sample size).\n",
    "#\n",
    "# table          There are two input types, usually automatically recognized by estimator_covariance:\n",
    "#                1) A two dimensional numpy array containing the allele counts on the individual level. Rows are SNPs, columns are\n",
    "#                   individuals. If the allele count is nowhere 2, you need to use the optional parameter input_type = 1.\n",
    "#                2) A two dimensional numpy array containing the allele frequencies on the population level. Rows are SNPs, columns are\n",
    "#                   populations. If the allele frequency is always either 0 or 1, you need to use the optional parameter input_type = 2.\n",
    "#                You can use the function counts_to_frequencies to transmute table and populations from input type 1) to input type 2).\n",
    "# populations    There are two input types, usually automatically recognized by estimator_covariance:\n",
    "#                1) A one dimensional numpy array containing the name of the population each individual belongs to, in the order the\n",
    "#                   individuals appear as the columns of table. Thus, each population name can appear once or many times.\n",
    "#                2) A one dimensional numpy array containing the names of the populations, in the order they appear as the columns of\n",
    "#                   table.\n",
    "#                You can use the function counts_to_frequencies to transmute table and populations from input type 1) to input type 2).\n",
    "# window         The size of the blocks used by the resampling methods in SNPs. The sesampling requires i.i.d. random variables but the\n",
    "#                independence of consecutive samples is not very well satisfied, using blocks helps with that. I don't have a very good\n",
    "#                idea on what would be a justified block size. Any data at the end of table that doesn't fill a whole block is discarded.\n",
    "# statistic      The name of the preset statistic collection. Overruled if user defined statistics are given by M and names.\n",
    "#                Let P be number of populations and x_1, x_2, ..., x_P the allele frequencies of a SNP in those populations.\n",
    "#                By a statistic I mean (the expected value over all SNPs of) a homogeneous second degree polynomial on the x_i.\n",
    "#                The dimension of the linear space spanned by all the possible statistics is P(P + 1)/2, as the space is spanned by\n",
    "#                the linearly independent polynomials x_1^2, x_1x_2, ..., x_1x_P, x_2^2, x_2x_3, x_2x_4, ..., x_2x_P, ..., x_P^2.\n",
    "#                \"basis\"     The default value. Consists of all the (P - 1)P/2 f2-statistics (x_i - x_j)^2 (i not j) and P f3-statistics\n",
    "#                            of the form (x_i - x_(i - 1))(x_i - x_(i + 1)) (addition of indices done modulo P).\n",
    "#                            In total that's P(P + 1)/2 statistics that are linearly independent and span the whole statistic space.\n",
    "#                \"f2_basis\"  All the (P - 1)P/2 f2-statistics of the form (x_i - x_j)^2 (i < j). They are a linearly independent set that\n",
    "#                            spans the whole subspace generated by all the f2-statistics.\n",
    "#                \"f2_all\"    All the (P - 1)P f2-statistics (x_i - x_j)^2 (i not j). They do not form a linearly independent set, and so\n",
    "#                            the covariance matrix of the sample mean will be only positive semidefinite, and thus singular.\n",
    "#                            That's why you cannot select output_type = 3.\n",
    "#                \"f3_subset\" There exists no nice basis made of f3-statistics for the P(P + 1)/2-dimensional subspace spanned by the\n",
    "#                            f3-statistics. This is just the P linearly independent f3-statistics (x_i - x_(i - 1))(x_i - x_(i + 1))\n",
    "#                            (addition of indices done modulo P). I use this to make \"basis\", by itself probably not interesting.\n",
    "#                \"f3_all\"    All the (P - 2)(P - 1)P f3-statistics (x_i - x_j)(x_i - x_k) (i, j and k different). They do not form a\n",
    "#                            linearly independent set, and so the covariance matrix of the sample mean will be only positive semidefinite,\n",
    "#                            and thus singular. That's why you cannot select output_type = 3.\n",
    "#                \"f4_basis\"  A collection of (P - 3)P/2 linearly independent f4-statistics (x_i - x_(i + 1))(x_j - x_(j + 1)) (addition of\n",
    "#                            indices done modulo P, i - j not - 1, 0 or 1). They span the whole (P - 3)P/2-dimensional subspace generated\n",
    "#                            by all the f4-statistics.\n",
    "#                \"f4_all\"    All the (P - 3)(P - 2)(P - 1)P f4-statistics (x_i - x_j)(x_k - x_l) (i, j, k and l different). They do not\n",
    "#                            form a linearly independent set, and so the covariance matrix of the sample mean will be only positive\n",
    "#                            semidefinite, and thus singular. That's why you cannot select output_type = 3.\n",
    "#                The statistic naming convention in all of the preset settings is that the name of f4(W, X; Y, Z), where W, X, Y and Z\n",
    "#                are some populations (corresponds to the homogeneous polynomial (w - x)(y - z), where w, x, y and z are allele\n",
    "#                frequencies of a SNP in populations W, X, Y and Z, respectively) is \"W X Y Z\". (This is the format the R package\n",
    "#                admixturegraph uses.) Note that f2(X, Y) = f4(X, Y; X, Y) and f3(X; Y, Z) = f4(X, Y; X, Z).\n",
    "# M              An optional parameter for overruling preset statistics (together with names). A two dimensional numpy array that codes\n",
    "#                the homogeneous polynomials corresponding to your desired statistics as columns. More precisely w = vM, where\n",
    "#                v = [x_1^2, x_1x_2, ..., x_1x_P, x_2^2, x_2x_3, x_2x_4, ..., x_2x_P, ..., x_P^2] and w is a row vector of your S new\n",
    "#                statistics. Note that if deg(M) < S, the new statistics are linearly dependent, the covariance matrix of the sample mean\n",
    "#                will be only positive semidefinite and thus singular, and so you cannot select output_type = 3.\n",
    "# names          An optional parameter for overruling preset statistics (together with M). A one dimensional numpy array containing the\n",
    "#                names for the S new statistics coded by M.\n",
    "# resampling     The resampling method used for estimating the covariance of the sample mean of the statistic collection.\n",
    "#                \"jackknife\" The default value. Using the (block) jackknife method.\n",
    "#                \"bootstrap\" (Actually any other value than \"jackknife\".) Using the (block) bootsrap method with B bootstrap resamples.\n",
    "# B              An optional parameter for the number of resamples when using the bootstrap method. Defaults at the number of blocks.\n",
    "# input_type     An optional parameter for helping estimator_covariance to recognize whether it was given allele counts or allele\n",
    "#                frequencies. Only needed when table has only zeros or ones, then use input_type = 1 for input type 1) (allele counts)\n",
    "#                and input_type = 2 for input type 2) (allele frequencies). Defaults at input_type = 0, which is attempting to recognize\n",
    "#                the input type automatically.\n",
    "# output_type    An optional parameter deciding how estimator_covariance returns the covariance matrix (second element of the output).\n",
    "#                1 The default value. Gives an estimate for the covariance matrix of the sample mean, let's call it S.\n",
    "#                2 Gives a matrix s such that s^Ts = S.\n",
    "#                3 Gives the inverse of s. Nothe that if the statistic collection is not linearly independent, the inverse does not\n",
    "#                  exist and you cannot select output_type = 3. This matrix directly applicable to the R package admixturegraph.\n",
    "# save           An optional string, if present will save the output in text files. The file \"<save>_sm.txt\" contains the sample means\n",
    "#                of the statistics along with their names, and the file \"<save>_covariance_<output_type>.txt\" contains the matrix\n",
    "#                decided by output_type (the second element of the output, the covariance matrix of the sample means by default).\n",
    "#\n",
    "# The function returns a list of three things:\n",
    "# [0] The sample mean of the collection of statistics used (either preset or user defined).\n",
    "# [1] What output_type dictates. Defaults at the covariance matrix of the sample mean in [0].\n",
    "# [2] The names of the collection of statistics used, either preset or user defined.\n",
    "def estimator_covariance(table,\n",
    "                         populations,\n",
    "                         window,\n",
    "                         statistic = \"basis\",\n",
    "                         M = None,\n",
    "                         names = None,\n",
    "                         resampling = \"jackknife\",\n",
    "                         B = None,\n",
    "                         input_type = 0,\n",
    "                         output_type = 1,\n",
    "                         save = \"\"):\n",
    "    # Before proceeding, let's see if there will be problems with output_type = 3.\n",
    "    if output_type == 3:\n",
    "        if numpy.all(M) == None: # Using preset statistics.\n",
    "            if statistic == \"f2_all\":\n",
    "                print(\"You cannot choose output_type = 3 when using the preset statistics 'f2_all' because the statistics are not linearly independent and so the covariance matrix of the sample mean is not invertible.\")\n",
    "                return()\n",
    "            if statistic == \"f3_all\":\n",
    "                print(\"You cannot choose output_type = 3 when using the preset statistics 'f3_all' because the statistics are not linearly independent and so the covariance matrix of the sample mean is not invertible.\")\n",
    "                return()\n",
    "            if statistic == \"f4_all\":\n",
    "                print(\"You cannot choose output_type = 3 when using the preset statistics 'f4_all' because the statistics are not linearly independent and so the covariance matrix of the sample mean is not invertible.\")\n",
    "                return()\n",
    "        else: # Using user defined statistics.\n",
    "            if numpy.linalg.matrix_rank(M) < M.shape[1]:\n",
    "                print(\"You cannot choose output_type = 3 because the statistics coded by the matrix M you gave are not linearly independent and so the covariance matrix of the sample mean is not invertible.\")\n",
    "                return()\n",
    "    # Start by sampling in windows of size window, using the function sample.\n",
    "    (table, populations) = sample(table, populations, window, input_type)\n",
    "    # Now approximate the covariance matrix of the sample mean using either jackknifing or bootstrapping.\n",
    "    if resampling == \"jackknife\":\n",
    "        resample = jackknife(table)\n",
    "    else:\n",
    "        resample = bootstrap(table, B)\n",
    "    (sm, cov) = resample\n",
    "    # For covariances between linear combinations of the original statistics it's convenient to split the covariance matrix into a\n",
    "    # product of a matrix and its transpose.\n",
    "    ec = numpy.linalg.eigh(cov)\n",
    "    half = numpy.diag(numpy.sqrt(numpy.absolute(ec[0])))@ec[1].T # The half transposed times half is cov.\n",
    "    # Transform the covariance matrix to concern the statistics the user is interested in.\n",
    "    if numpy.all(M) == None: # Using preset statistics.\n",
    "        if statistic == \"basis\":\n",
    "            (M, names) = basis(populations)\n",
    "        elif statistic == \"f2_basis\":\n",
    "            (M, names) = f2_basis(populations)\n",
    "        elif statistic == \"f2_all\":\n",
    "            (M, names) = f2_all(populations)\n",
    "        elif statistic == \"f3_subset\":\n",
    "            (M, names) = f3_subset(populations)\n",
    "        elif statistic == \"f3_all\":\n",
    "            (M, names) = f3_all(populations)\n",
    "        elif statistic == \"f4_basis\":\n",
    "            (M, names) = f4_basis(populations)\n",
    "        elif statistic == \"f4_all\":\n",
    "            (M, names) = f4_all(populations)\n",
    "        else:\n",
    "            print(\"Invalid preset statistics, use 'basis', 'f2_basis', 'f2_all', 'f3_subset', 'f3_all', 'f4_basis', 'f4_all', or your own parameters M and names.\")\n",
    "            return()\n",
    "    sm = M.T@sm\n",
    "    half = half@M\n",
    "    cov = half.T@half\n",
    "    if output_type == 1:\n",
    "        result = cov\n",
    "    if output_type == 2:\n",
    "        ec = numpy.linalg.eigh(cov)\n",
    "        half = numpy.diag(numpy.sqrt(numpy.absolute(ec[0])))@ec[1].T\n",
    "        result = half\n",
    "    if output_type == 3:\n",
    "        ec = numpy.linalg.eigh(cov)\n",
    "        half = numpy.diag(numpy.sqrt(numpy.absolute(ec[0])))@ec[1].T\n",
    "        result = numpy.linalg.inv(half)\n",
    "    if save != \"\":\n",
    "        sm_filename = save + \"_sm.txt\"\n",
    "        with open(sm_filename, \"w\") as f:\n",
    "            for i in range(0, len(sm)):\n",
    "                f.write(names[i])\n",
    "                f.write(\" \")\n",
    "                f.write(str(sm[i, 0]))\n",
    "                if i < len(sm) - 1:\n",
    "                    f.write(\"\\n\")\n",
    "        result_filename = save + \"_covariance_\" + str(output_type) + \".txt\"\n",
    "        with open(result_filename, \"w\") as f:\n",
    "            for i in range(result.shape[0]):\n",
    "                for j in range(result.shape[1]):\n",
    "                    f.write(str(result[i, j]))\n",
    "                    if j < result.shape[1] - 1:\n",
    "                        f.write(\" \")\n",
    "                if i < result.shape[0] - 1:\n",
    "                    f.write(\"\\n\")\n",
    "    return(sm, result, names)\n",
    "    \n",
    "########## THE SAMPLER FUNCTION  ##########################################################################################################\n",
    "\n",
    "# sample\n",
    "# Given either allele counts of individuals or allele frequencies of populations, the function sample will compute sample means of all\n",
    "# the second degree homogeneous monomials of allele frequencies in blocks. \n",
    "# \n",
    "# table          There are two input types, usually automatically recognized by sample:\n",
    "#                1) A two dimensional numpy array containing the allele counts on the individual level. Rows are SNPs, columns are\n",
    "#                   individuals. If the allele count is nowhere 2, you need to use the optional parameter input_type = 1.\n",
    "#                2) A two dimensional numpy array containing the allele frequencies on the population level. Rows are SNPs, columns are\n",
    "#                   populations. If the allele frequency is always either 0 or 1, you need to use the optional parameter input_type = 2.\n",
    "#                You can use the function counts_to_frequencies to transmute table and populations from input type 1) to input type 2).\n",
    "# populations    There are two input types, usually automatically recognized by sample:\n",
    "#                1) A one dimensional numpy array containing the name of the population each individual belongs to, in the order the\n",
    "#                   individuals appear as the columns of table. Thus, each population name can appear once or many times.\n",
    "#                2) A one dimensional numpy array containing the names of the populations, in the order they appear as the columns of\n",
    "#                   table.\n",
    "#                You can use the function counts_to_frequencies to transmute table and populations from input type 1) to input type 2).\n",
    "# window         The size of the blocks the sample means are computed over. Any data at the end of table that doesn't fill a whole block\n",
    "#                is discarded.\n",
    "# input_type     An optional parameter for helping sample to recognize whether it was given allele counts or allele frequencies.\n",
    "#                Only needed when table has only zeros or ones, then use input_type = 1 for input type 1) (allele counts) and\n",
    "#                input_type = 2 for input type 2) (allele frequencies). Defaults at input_type = 0, which is attempting to recognize\n",
    "#                the input type automatically.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] A two dimensional numpy array consisting of some number of sample means of the P(P + 1)/2 homoheneous second degree monomials\n",
    "#     x_1^2, x_1x_2, ... , x_1x_P, x_2^2, x_2x_3, ..., x_2x_P, ..., x_P^2, where x_i is the allele frequency of a SNP in the i:th\n",
    "#     population and P is the number of populations. Rows are monomials, columns are samples.\n",
    "#     The size of each sample block is determined by the parameter window; SNPs at the end that do not fill a whole window are discarded.\n",
    "# [1] The population names (which could be new information if using the input type 1)).\n",
    "def sample(table, populations, window, input_type = 0):\n",
    "    # Let's do what we can to detect the input type:\n",
    "    if input_type == 0:\n",
    "        for i in range(0, table.shape[0]):\n",
    "            for j in range(0, table.shape[1]):\n",
    "                if table[i, j] == 2:\n",
    "                    input_type = 1 # Input type is definitely 1).\n",
    "                    break\n",
    "                if 0 < table[i, j] < 1:\n",
    "                    input_type = 2 # Input type is definitely 2).\n",
    "                    break\n",
    "            if input_type != 0:\n",
    "                break\n",
    "    if input_type == 0:\n",
    "        print(\"I don't know whether your input is allele counts of individuals (use parameter input_type = 1) or allele frequencies of populations (use parameter input_type = 2)\")\n",
    "        return()\n",
    "    if input_type == 1: # Assuming 1).\n",
    "        (table, populations) = counts_to_frequencies(table, populations)\n",
    "        input_type = 2\n",
    "    if input_type == 2: # Assuming 2).\n",
    "        # Start by creating an output file of the right size.\n",
    "        P = len(populations) # Number of populations.\n",
    "        S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "        W = int(table.shape[0]/window) # Number of windows.\n",
    "        sample = numpy.empty([S, W]) # The result, contains what ever for now.\n",
    "        # Then we proceed one window at a time, recording the sample mean of each second degree term.\n",
    "        for w in range(W):\n",
    "            t = 0 # A counter.\n",
    "            for i in range(0, P):\n",
    "                A = table[range(w*window, (w + 1)*window), i].T\n",
    "                for j in range(i, P):\n",
    "                    B = table[range(w*window, (w + 1)*window), j]\n",
    "                    sample[t, w] = A@B/window\n",
    "                    t += 1\n",
    "    return(sample, populations)\n",
    "\n",
    "########## RESAMPLING FUNCTIONS ###########################################################################################################\n",
    "\n",
    "# jackknife\n",
    "# Given samples of a (multidimensional) i.i.d. random variable, the function jackknife computes the sample mean and the covariance\n",
    "# matrix of the sample mean (not the random variable) using the jackknife method.\n",
    "#\n",
    "# table    A two dimensional numpy array containing samples of an i.i.d. random variable.\n",
    "#          Rows are coordinates and columns are iterations. The first coordinate of the output of the function sample is suitable.\n",
    "#\n",
    "# The output is a list of two things:\n",
    "# [0] A one dimensional numpy array containing the sample mean of the (multidimensional) random variable.\n",
    "# [1] A two dimensional numpy array containing the covariance matrix of that sample mean.\n",
    "def jackknife(table):\n",
    "    B = table.shape[1] # The number of resamplings.\n",
    "    # Start by computing the sample mean.\n",
    "    sm = table@numpy.ones([B, 1])/B\n",
    "    # Then compute the covariance matrix of the sample mean.\n",
    "    cov = numpy.zeros([table.shape[0], table.shape[0]])\n",
    "    for i in range(0, B):\n",
    "        # What I'm doing might not look like jackknifing but it is equivalent.\n",
    "        v = numpy.asarray(numpy.asmatrix(table)[:, i]) - sm\n",
    "        cov += v@v.T\n",
    "    cov = cov/((B - 1)*B)\n",
    "    return(sm, cov)\n",
    "\n",
    "# bootstrap\n",
    "# Given samples of a (multidimensional) i.i.d. random variable, the function bootstrap computes the sample mean and the covariance\n",
    "# matrix of the sample mean (not the random variable) using the bootstrap method.\n",
    "# This is slower than jackknife but should also be better with large values of B.\n",
    "# If you are interested in the sample mean only and not its covariance matrix, you can use this function with B = 2 (for speed).\n",
    "#\n",
    "# table    A two dimensional numpy array containing samples of an i.i.d. random variable.\n",
    "#          Rows are coordinates and columns are iterations. The first coordinate of the output of the function sample is suitable.\n",
    "# B        An optional parameter for the number of resamples. Defaults at the number of original samples.\n",
    "#\n",
    "# The output is a list of two things:\n",
    "# [0] A one dimensional numpy array containing the sample mean of the (multidimensional) random variable.\n",
    "# [1] A two dimensional numpy array containing the covariance matrix of that sample mean.\n",
    "def bootstrap(table, B = None):\n",
    "    if B == None:\n",
    "        B = table.shape[1]\n",
    "    # Start by computing the sample mean.\n",
    "    sm = table@numpy.ones([table.shape[1], 1])/table.shape[1]\n",
    "    # Perform the bootstrap resampling.\n",
    "    boots = numpy.empty([table.shape[0], B])\n",
    "    for i in range(0, B):\n",
    "        u = bootstrap_vector(table.shape[1])\n",
    "        boots[:, i] = (table@u/table.shape[1]).T\n",
    "    # Next we need the sample mean of the bootstrap resamples.\n",
    "    bsm = boots@numpy.ones([B, 1])/B\n",
    "    # Then compute the covariance matrix of the sample mean.\n",
    "    cov = numpy.zeros([table.shape[0], table.shape[0]])\n",
    "    for i in range(0, B):\n",
    "        v = numpy.asarray(numpy.asmatrix(boots)[:, i]) - bsm\n",
    "        cov += v@v.T\n",
    "    cov = cov/(B - 1)\n",
    "    return(sm, cov)\n",
    "\n",
    "########### AUXILIARY FUNCTIONS ###########################################################################################################\n",
    "\n",
    "# counts_to_frequencies\n",
    "# The function counts_to_frequencies is used to convert table and populations of input type 1) (allele counts) into input type 2) \n",
    "# (ellele frequencies) for the functions estimator_covariance and sample.\n",
    "#\n",
    "# table          A two dimensional numpy array containing the allele counts on the individual level. Rows are SNPs, columns are\n",
    "#                individuals.\n",
    "# populations    A one dimensional numpy array containing the name of the population each individual belongs to, in the order the\n",
    "#                individuals appear as the columns of table. Thus, each population name can appear once or many times.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] A two dimensional numpy array containing the allele frequencies on the population level. Rows are SNPs, columns are populations.\n",
    "# [1] A one dimensional numpy array containing the names of the populations, in the order they appear as the columns of table.\n",
    "#     The new populations are list(set(populations)), so the original order af appearance from the input might not be kept. \n",
    "def counts_to_frequencies(table, populations):\n",
    "    new_populations = list(set(populations))\n",
    "    new_table = numpy.empty([table.shape[0], len(new_populations)])\n",
    "    for p in range(0, len(new_populations)):\n",
    "        v = numpy.where(populations == new_populations[p])[0]\n",
    "        new_table[:, p] = (table[:, v]@numpy.ones((len(v), 1))/len(v))[:, 0]\n",
    "    return(new_table, new_populations)\n",
    "\n",
    "# basis\n",
    "# The function basis creates the parameters M and names used by estimator_covariance with the default preset statistics \"basis\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the defaut preset statistic setting \"basis\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the default preset statistic setting \"basis\", see estimator_covariance.\n",
    "def basis(populations):\n",
    "    (M1, names1) = f2_basis(populations)\n",
    "    (M2, names2) = f3_subset(populations)\n",
    "    names = numpy.concatenate((names1, names2), 0)\n",
    "    M = numpy.concatenate((M1, M2), 1)\n",
    "    return(M, names)\n",
    "\n",
    "# f2_basis\n",
    "# The function f2_basis creates the parameters M and names used by estimator_covariance with the preset statistics \"f2_basis\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f2_basis\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f2_basis\", see estimator_covariance.\n",
    "def f2_basis(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = int((P - 1)*P/2) # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    for i in range(0, P - 1):\n",
    "        for j in range(i + 1, P):\n",
    "            M[index(P, i, 0), t] = 1\n",
    "            M[index(P, j, 0), t] = 1\n",
    "            M[index(P, i, j - i), t] = - 2\n",
    "            names[t] = populations[i] + \" \" + populations[j] + \" \" + populations[i] + \" \" + populations[j]\n",
    "            t += 1\n",
    "    return(M, names)\n",
    "\n",
    "# f2_all\n",
    "# The function f2_all creates the parameters M and names used by estimator_covariance with the preset statistics \"f2_all\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f2_all\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f2_all\", see estimator_covariance.\n",
    "def f2_all(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = int((P - 1)*P) # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    for i in range(0, P):\n",
    "        for j in range(0, P):\n",
    "            if j != i:\n",
    "                M[index(P, i, 0), t] = 1\n",
    "                M[index(P, j, 0), t] = 1\n",
    "                M[index(P, numpy.minimum(i, j), numpy.absolute(i - j)), t] = - 2\n",
    "                names[t] = populations[i] + \" \" + populations[j] + \" \" + populations[i] + \" \" + populations[j]\n",
    "                t += 1\n",
    "    return(M, names)\n",
    "\n",
    "# f3_subset\n",
    "# The function f3_subset creates the parameters M and names used by estimator_covariance with the preset statistics \"f3_subset\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f3_subset\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f3_subset\", see estimator_covariance.\n",
    "def f3_subset(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = P # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    # The case i = 0 is dealt with separately.\n",
    "    M[index(P, 0, 0), t] = 1\n",
    "    M[index(P, 1, P - 2), t] = 1\n",
    "    M[index(P, 0, P - 1), t] = - 1\n",
    "    M[index(P, 0, 1), t] = - 1\n",
    "    names[t] = populations[0] + \" \" + populations[P - 1] + \" \" + populations[0] + \" \" + populations[1]\n",
    "    t += 1\n",
    "    for i in range(1, P - 1):\n",
    "        M[index(P, i, 0), t] = 1\n",
    "        M[index(P, i - 1, 2), t] = 1\n",
    "        M[index(P, i - 1, 1), t] = - 1\n",
    "        M[index(P, i, 1), t] = - 1\n",
    "        names[t] = populations[i] + \" \" + populations[i - 1] + \" \" + populations[i] + \" \" + populations[i + 1] + \" \"\n",
    "        t += 1\n",
    "    # The case i = P - 1 is dealt with separately.\n",
    "    M[index(P, P - 1, 0), t] = 1\n",
    "    M[index(P, 0, P - 2), t] = 1\n",
    "    M[index(P, P - 2, 1), t] = - 1\n",
    "    M[index(P, 0, P - 1), t] = - 1\n",
    "    names[t] = populations[P - 1] + \" \" + populations[P - 2] + \" \" + populations[P - 1] + \" \" + populations[0]\n",
    "    t += 1\n",
    "    return(M, names)\n",
    "\n",
    "# f3_all\n",
    "# The function f3_all creates the parameters M and names used by estimator_covariance with the preset statistics \"f3_all\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f3_all\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f3_all\", see estimator_covariance.\n",
    "def f3_all(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = int((P - 2)*(P - 1)*P) # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    for i in range(0, P):\n",
    "        for j in range(0, P):\n",
    "            if j != i:\n",
    "                for k in range(0, P):\n",
    "                    if k != i:\n",
    "                        if k != j:\n",
    "                            M[index(P, i, 0), t] = 1\n",
    "                            M[index(P, numpy.minimum(j, k), numpy.absolute(j - k)), t] = 1\n",
    "                            M[index(P, numpy.minimum(i, j), numpy.absolute(i - j)), t] = - 1\n",
    "                            M[index(P, numpy.minimum(i, k), numpy.absolute(i - k)), t] = - 1\n",
    "                            names[t] = populations[i] + \" \" + populations[j] + \" \" + populations[i] + \" \" + populations[k]\n",
    "                            t += 1\n",
    "    return(M, names)\n",
    "                    \n",
    "# f4_basis\n",
    "# The function f4_basis creates the parameters M and names used by estimator_covariance with the preset statistics \"f4_basis\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f4_basis\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f4_basis\", see estimator_covariance.\n",
    "def f4_basis(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = int((P - 3)*P/2) # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    # The case i = P - 1 is dealt with separately.\n",
    "    for j in range(1, P - 2):\n",
    "        M[index(P, 0, j + 1), t] = 1\n",
    "        M[index(P, j, P - j - 1), t] = 1\n",
    "        M[index(P, 0, j), t] = - 1\n",
    "        M[index(P, j + 1, P - j - 2), t] = - 1\n",
    "        names[t] = populations[P - 1] + \" \" + populations[0] + \" \" + populations[j] + \" \" + populations[j + 1]\n",
    "        t += 1\n",
    "    for i in range(0, P - 1):\n",
    "        for j in range(i + 2, P - 1):\n",
    "            M[index(P, i, j - i), t] = 1\n",
    "            M[index(P, i + 1, j - i), t] = 1\n",
    "            M[index(P, i, j - i + 1), t] = - 1\n",
    "            M[index(P, i + 1, j - i - 1), t] = - 1\n",
    "            names[t] = populations[i] + \" \" + populations[i + 1] + \" \" + populations[j] + \" \" + populations[j + 1]\n",
    "            t += 1\n",
    "    return(M, names)\n",
    "\n",
    "# f4_all\n",
    "# The function f4_all creates the parameters M and names used by estimator_covariance with the preset statistics \"f4_all\".\n",
    "#\n",
    "# populations    A one dimensional numpy array of populations.\n",
    "#\n",
    "# The function returns a list of two things:\n",
    "# [0] The matrix M corresponding to the preset statistic setting \"f4_all\", see estimator_covariance.\n",
    "# [1] The array of statistic names corresponding to the preset statistic setting \"f4_all\", see estimator_covariance.\n",
    "def f4_all(populations):\n",
    "    P = len(populations) # The number of populations.\n",
    "    S = int(P*(P + 1)/2) # The number of second degree terms.\n",
    "    F = int((P - 3)*(P - 2)*(P - 1)*P) # The number of statistics.\n",
    "    M = numpy.zeros((S, F)) # The matrix coding the statistics in terms of the second degree terms.\n",
    "    names = numpy.empty(F, dtype = object) # An empty array for the statistic names.\n",
    "    t = 0 # A counter.\n",
    "    for i in range(0, P):\n",
    "        for j in range(0, P):\n",
    "            if j != i:\n",
    "                for k in range(0, P):\n",
    "                    if k != i:\n",
    "                        if k != j:\n",
    "                            for l in range(0, P):\n",
    "                                if l != i:\n",
    "                                    if l != j:\n",
    "                                        if l != k:\n",
    "                                            M[index(P, numpy.minimum(i, k), numpy.absolute(i - k)), t] = 1\n",
    "                                            M[index(P, numpy.minimum(j, l), numpy.absolute(j - l)), t] = 1\n",
    "                                            M[index(P, numpy.minimum(i, l), numpy.absolute(i - l)), t] = - 1\n",
    "                                            M[index(P, numpy.minimum(j, k), numpy.absolute(j - k)), t] = - 1\n",
    "                                            names[t] = populations[i] + \" \" + populations[j] + \" \" + populations[k] + \" \" + populations[l]\n",
    "                                            t += 1\n",
    "    return(M, names)\n",
    "\n",
    "# index\n",
    "# The function index returns the ordinal of an element (r, r + d), d >= 0, from the diagonal or the upper triangle of a PxP-table,\n",
    "# when ordered first by rows and then by columns.\n",
    "#\n",
    "# P    The size of the table.\n",
    "# r    The row of the element in question.\n",
    "# d    The diagional (the column minus the row) of the element in question.\n",
    "#\n",
    "# The function returns the ordinal of the element in question when the table is ordered by rows first, then columns.\n",
    "def index(P, r, d):\n",
    "    return(int(d + r*(P - (r - 1)/2)))\n",
    "\n",
    "# bootsrap_vector\n",
    "# The function bootsrap_vector returns the sum of n vectors uniformly randomly chosen from the elementary basis vectors of length n.\n",
    "#\n",
    "# n    It's a number. Beginning to think that too strict consistency in documenting style is not worth it :-P\n",
    "#\n",
    "# The function returns the sum of n vectors uniformly randomly chosen from the elementary basis vectors of length n.\n",
    "def bootstrap_vector(n):\n",
    "    u = numpy.zeros(n)\n",
    "    for i in range(0, n):\n",
    "        u[numpy.random.randint(0, n)] += 1\n",
    "    return(numpy.asarray(numpy.asmatrix(u).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.all(5) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
